Nomenclature 
============

OpenCL has global_work_size, local_work_size, work-groups and work_items
CUDA has grids, blocks, threads

In OpenCL, the local_work_size subdivides the global_work_size
In CUDA. the grid consists of blocks

* jobs, local global, group
* threads, local global, group
* work, local, global, group
* block
* grid
* group
* domain
* cluster
* pack
* gang
* fiber
* lot
* assembly
* batch
* bundle
* fiber bundle
* packet
* lattice
* weave
* mesh
* netting
* net
* megafiber
* gigafiber
* lattice
* divisor
* denominator
* distribution
* fragmentation
* partition
* split
* sectioning
* layout
* fragmentation
* communition
* solvent
* fabric
* cells



fiber, fiber bundle, fiber bundle group
fiber, bundle, mesh <-
spark, flame, blaze
fiber, bundle, cluster
fiber, fiber_bundle, fiber_fabric
fiber, fiber_bundle, fibre_grid

for work-group/block:
synchronization domain 
single instruction domain (SIMD)

I prefer the "subdividing" nomanclature over the "consists of" way of
defining and partitioning work. It is a lot simpler. Or is it?

I think fiber, bundle and mesh are suitable metaphors for partitioning
work in the CUDA/OpenCL way.

fiber, bundle, cluster? 
fiber, fiber_bundle, fiber_cluster?
fiber, fiber_bundle, fiber_mesh?
stream, bundle, cluster?

Now should it be fiber_bundle, fiber_mesh

-----


OpenCL has command queues, CUDA has streams

I need a new word that encompasses both
The word should generalize on execution path (German: Ausfuehrungspfad),
or execution environment or execution envelope or something like this.
The word must be the name of the template argument for all library functions
that require an execution environment. Some options:

* fiber: this would be kind of a new concept but maybe it makes sense, since
it is not a thread but a concurrent environment
* execution path: to long
* task queue
* spark: a concept from haskell 
* transaction
* coroutine: a concept from concurrency research
* channel
* execution stream
* instruction stream
* command stream
* domain
* execution site
* execution context, exec_context, execution_context
* activity stream
* sequence
* isolate (from google dart)
* command set
* creek
* flood
* torrent
* pipeline 
* beam
* ray
* flurry
* breeze (this is nice and fits Aura)
* squall
* wave
* current (this is also nice)
* batch
* feed (wow, feed it nice)


The concept I am trying to name is in essence concurrency. It is an independent
stream of instructions. The programmer explicitly marks theses instructions
as independent. If the hardware is capable, these instructions can be executed
in parallel.

The concept encompasses both a location of execution (accelerator) but also a 
logical group of execution (concurrency).

I think execution context might be the correct phrase, it can be either a 
device or a stream.

Actually no. There should be just 2 concepts: a device (execution site) and 
an execution stream allowing some form of concurrency. The question now is, 
how should they be interlinked and do they have to be interlinked. If they
should be interlinked, this will certainly have to be done with thread-safe
data structures that could degrade performance and increase complexity at
an already very low level. So maybe this can be avoided. Once concsequence is
that we can not have a device_synchronize(device) functin because neither 
OpenCL nor CUDA actually provide that. If we wanted to do that we would need
to store all streams and and command queues somewhere. So we only provide
stream synchronization.

Let's call it breeze. Well, breeze fits the Aura metaphor nicely but I
think feed is a more accurate word for it. A device feed. Nice. 



The type representing a file containing kernel code (fatbin, ptx, cl-source)
requires a name.

kernel_code_file
kernel_file
module_file
backend_file

